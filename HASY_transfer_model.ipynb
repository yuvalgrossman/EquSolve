{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HASY transfer model.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1hxVc7ahATrnP4C7zJI9NoPQPXBMQjmIB",
      "authorship_tag": "ABX9TyO/UuKhVDg3CLaC1HR7PUwJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuvalgrossman/EquSolve/blob/master/HASY_transfer_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSBVcRY0R1uM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "8188bbff-59c7-48f2-87d2-c018955c7aa7"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tarfile\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim \n",
        "import pdb\n",
        "import time\n",
        "from PIL import Image\n",
        "\n",
        "!wget 'https://zenodo.org/record/259444/files/HASYv2.tar.bz2?download=1'\n",
        "my_tar = tarfile.open('HASYv2.tar.bz2?download=1')\n",
        "my_tar.extractall() # specify which folder to extract to\n",
        "my_tar.close()\n",
        "!git clone https://github.com/yuvalgrossman/EquSolve\n",
        "\n",
        "from EquSolve.Utils.mapper import mapper\n",
        "from EquSolve.Classifier.HASYDataLoader import ExampleDataset"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-25 10:57:24--  https://zenodo.org/record/259444/files/HASYv2.tar.bz2?download=1\n",
            "Resolving zenodo.org (zenodo.org)... 188.184.117.155\n",
            "Connecting to zenodo.org (zenodo.org)|188.184.117.155|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 34597561 (33M) [application/octet-stream]\n",
            "Saving to: ‘HASYv2.tar.bz2?download=1.1’\n",
            "\n",
            "HASYv2.tar.bz2?down 100%[===================>]  32.99M  6.74MB/s    in 4.9s    \n",
            "\n",
            "2020-08-25 10:57:31 (6.74 MB/s) - ‘HASYv2.tar.bz2?download=1.1’ saved [34597561/34597561]\n",
            "\n",
            "fatal: destination path 'EquSolve' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alvW6_bpWMgF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 0.01\n",
        "momentum = 0.9\n",
        "n_epochs = 10\n",
        "batch_size = 10"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8u1oFV5T3E9S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class HASYDataset(Dataset):\n",
        "    def __init__(self, config, csv_df,transforms):\n",
        "        self.config = config\n",
        "        self.data = csv_df\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data.index)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        y = self.data.loc[idx, 'symbol_id']\n",
        "        img_path = self.config['data_path'] + self.data.loc[idx, 'path']\n",
        "        img = Image.open(img_path) # load image in PIL format\n",
        "        X = self.transforms(img)   # apply transforms: resize-> tensor-> normalize\n",
        "        X_reshape = X[0].unsqueeze(-1).transpose(2,0) # reshape to [1,28,28]\n",
        "        return (X_reshape, y)\n",
        "\n",
        "    def plotitem(self, idx):\n",
        "        y = self.data.loc[idx, 'latex']\n",
        "        # X = plt.imread(self.config['data_path'] + self.data.loc[idx, 'path'][6:])[:, :, 0]\n",
        "        X = plt.imread(self.config['data_path'] + self.data.loc[idx, 'path'])[:, :, 0]\n",
        "\n",
        "        plt.imshow(X)\n",
        "        plt.title(y)\n",
        "        print('img size {}'.format(X.shape))\n",
        "        # print((X[:,:,2]==X[:,:,0]).all())\n",
        "        # print((X[:,:,2]==X[:,:,1]).all())"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bULs6wh2LJPU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "ab8d1f5b-f195-4b52-ef54-5250e59ca45c"
      },
      "source": [
        "meta_data = pd.read_csv('hasy-data-labels.csv')\n",
        "sym_list = ['1','2','3','4','5','6','7','8','9','\\\\alpha','=','+','-','\\\\pi','A','X','\\\\cdot']\n",
        "all_df = mapper(meta_data,sym_list)\n",
        "all_df.latex.value_counts()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\\alpha    2601\n",
              "\\pi       1533\n",
              "\\cdot      755\n",
              "A          159\n",
              "2          124\n",
              "8          121\n",
              "3          120\n",
              "1          118\n",
              "-          118\n",
              "6          100\n",
              "9           90\n",
              "+           90\n",
              "5           78\n",
              "7           75\n",
              "4           61\n",
              "X           54\n",
              "Name: latex, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifQSTmAfYfvv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "n_classes = len(sym_list)\n",
        "train_split = 0.8\n",
        "config = {'data_path':''}\n",
        "transform = transforms.Compose([transforms.Resize([28,28]),                                \n",
        "                      transforms.ToTensor(),\n",
        "                      transforms.Normalize(0.5,0.5),\n",
        "                      ])\n",
        "dataset = HASYDataset(config,all_df,transform)\n",
        "\n",
        "train_size = int(train_split * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmmiTHD3TVAJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "32660fe3-c648-45bf-c133-0ddc3ecf32ca"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x))); \n",
        "        x = self.pool(F.relu(self.conv2(x)));\n",
        "        x = x.view(-1, 16 * 4 * 4); \n",
        "        x = F.relu(self.fc1(x)); \n",
        "        x = F.relu(self.fc2(x));\n",
        "        x = self.fc3(x);\n",
        "        return x\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "net = Net().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=lr, momentum=momentum)\n",
        "net.load_state_dict(torch.load('EquSolve/MNISTnet.pth', map_location=lambda storage, loc: storage)) # map to CPU\n",
        "\n",
        "for param in net.parameters():\n",
        "  print(param.shape)\n",
        "  # param.requires_grad = False # freeze model weights\n",
        "\n",
        "net.fc3 = nn.Linear(84,n_classes)\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n",
            "torch.Size([6, 1, 5, 5])\n",
            "torch.Size([6])\n",
            "torch.Size([16, 6, 5, 5])\n",
            "torch.Size([16])\n",
            "torch.Size([120, 256])\n",
            "torch.Size([120])\n",
            "torch.Size([84, 120])\n",
            "torch.Size([84])\n",
            "torch.Size([10, 84])\n",
            "torch.Size([10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsTSlUWiRgsX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test():\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        images, labels = data\n",
        "        outputs = net(images.to(device))\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels.to(device)).sum().item()\n",
        "  print('model accuracy: %d %%' % (100 * correct / total))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_hVA7jrWytX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "fd31591f-5a38-42a7-ebdf-54207e81d786"
      },
      "source": [
        "net.train()\n",
        "for epoch in range(n_epochs):  # loop over the dataset multiple times\n",
        "    t = time.time()\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        \n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs.to(device))\n",
        "        loss = criterion(outputs, labels.to(device))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    \n",
        "    # print statistics\n",
        "    print('epoch {} loss:{:.3f} time:{:.3f}'.format(epoch + 1, loss.item(), time.time()-t))\n",
        "    test()\n",
        "    \n",
        "\n",
        "print('Finished Training')\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 1 loss:0.033 time:4.689\n",
            "model accuracy: 88 %\n",
            "epoch 2 loss:0.139 time:4.549\n",
            "model accuracy: 95 %\n",
            "epoch 3 loss:0.010 time:4.500\n",
            "model accuracy: 96 %\n",
            "epoch 4 loss:0.029 time:4.519\n",
            "model accuracy: 97 %\n",
            "epoch 5 loss:0.001 time:4.508\n",
            "model accuracy: 96 %\n",
            "epoch 6 loss:0.015 time:4.518\n",
            "model accuracy: 97 %\n",
            "epoch 7 loss:0.004 time:4.490\n",
            "model accuracy: 97 %\n",
            "epoch 8 loss:0.182 time:4.486\n",
            "model accuracy: 96 %\n",
            "epoch 9 loss:0.000 time:4.444\n",
            "model accuracy: 97 %\n",
            "epoch 10 loss:0.000 time:4.460\n",
            "model accuracy: 97 %\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlLFRukOVB4v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1ed426ac-2865-4639-c23c-739886b237b2"
      },
      "source": [
        "n_classes\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    }
  ]
}