{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HASY_trainer.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOuvMH6i4ySczFyYdTel+Xn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuvalgrossman/EquSolve/blob/master/Classifier/HASY_trainer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAqqBRMGYo0X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "58bc9037-ab8f-4dc8-b126-e3daae196fdd"
      },
      "source": [
        "import os\n",
        "%cd '/content/'\n",
        "if not os.path.isdir('EquSolve'):\n",
        "  !git clone http://github.com/yuvalgrossman/EquSolve\n",
        "  %cd EquSolve\n",
        "else:\n",
        "  %cd EquSolve\n",
        "  !git pull\n",
        "\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import transforms\n",
        "from tqdm import tqdm\n",
        "import webbrowser\n",
        "import time\n",
        "import pdb\n",
        "\n",
        "# project classes:\n",
        "from Classifier.HASYDataset import HASYDataset\n",
        "from Classifier.Net import Net\n",
        "from Utils.mapper import mapper"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'EquSolve'...\n",
            "warning: redirecting to https://github.com/yuvalgrossman/EquSolve/\n",
            "remote: Enumerating objects: 225, done.\u001b[K\n",
            "remote: Counting objects: 100% (225/225), done.\u001b[K\n",
            "remote: Compressing objects: 100% (179/179), done.\u001b[K\n",
            "remote: Total 225 (delta 101), reused 104 (delta 37), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (225/225), 21.06 MiB | 31.57 MiB/s, done.\n",
            "Resolving deltas: 100% (101/101), done.\n",
            "/content/EquSolve\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdLVN95gtHvg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Trainer():\n",
        "    def __init__(self, config, dataset):\n",
        "        self.config = config\n",
        "        self.device = self.get_device()\n",
        "        self.dataset = dataset\n",
        "\n",
        "        #create dir to save train results:\n",
        "        theTime = \"{date:%Y-%m-%d_%H-%M-%S}\".format(date=datetime.datetime.now())\n",
        "        self.Train_Results_Dir = 'Classifier/TrainResults/Train_Results_' + theTime\n",
        "        os.mkdir(self.Train_Results_Dir)\n",
        "\n",
        "        #create and open a webpage monitor: (we just replace one line in the html file to update the folder)\n",
        "        with open(\"Classifier/TrainResults/monitor_base.html\") as fin, open(\"Classifier/TrainResults/monitor.html\", 'w') as fout:\n",
        "            for line in fin:\n",
        "                lineout = line\n",
        "                if 'var results_folder' in line:\n",
        "                    lineout = 'var results_folder = \"Classifier/Train_Results_{}/\"'.format(theTime)\n",
        "                fout.write(lineout)\n",
        "\n",
        "        webbrowser.open(\"Classifier/TrainResults/monitor.html\")\n",
        "\n",
        "    def train(self):\n",
        "        # dataset should come as a tuple of (train_dataset,test_dataset)\n",
        "        train_data = self.dataset[0]\n",
        "        test_data = self.dataset[1]\n",
        "\n",
        "        # move dataset to dataloader\n",
        "        trainloader = DataLoader(train_data, batch_size=self.config['batch_size'], shuffle=True)\n",
        "        testloader = DataLoader(test_data, batch_size=self.config['batch_size'], shuffle=True)\n",
        "        \n",
        "        # TRAINING CONFIGURATIONS:\n",
        "        net = Net().to(self.device)\n",
        "        print(net)\n",
        "\n",
        "        # loss\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        # optimizer\n",
        "        self.optimizer = optim.SGD(net.parameters(), lr=self.config['lr'], momentum=self.config['momentum'])\n",
        "\n",
        "        # define tracking measures:\n",
        "        self.init_tracking_measures()\n",
        "\n",
        "        # apply network changes according to training state\n",
        "        if self.config['state'] == 'MNIST': # if training on MNIST\n",
        "            weights_save_path = self.config['weights_path'] + 'MNIST_weights.pth'\n",
        "\n",
        "        if self.config['state'] == 'HASY': # if training on HASY\n",
        "            weights_load_path = self.config['weights_path'] + 'MNIST_weights.pth'\n",
        "            weights_save_path = self.config['weights_path'] + 'HASY_weights.pth'\n",
        "\n",
        "            net.load_state_dict(torch.load(weights_load_path)['state_dict']) # load MNIST weights\n",
        "            net.fc3 = nn.Linear(84, len(config['sym_list']))   # change model's last layer\n",
        "\n",
        "\n",
        "        # TRAINING:\n",
        "        print('Start Training on {}'.format(self.device))\n",
        "\n",
        "        for epochNum in range(self.config['train_epochs']):  # no. of epochs\n",
        "\n",
        "            net = self.train_epoch(net, trainloader, epochNum)\n",
        "\n",
        "            self.test_epoch(net, testloader, epochNum)\n",
        "\n",
        "            self.generate_measures_plots() # update figures after each epoch to observe during training\n",
        "\n",
        "        self.save_network(net, weights_save_path)\n",
        "\n",
        "        print('Done Training {} epochs'.format(epochNum+1))\n",
        "\n",
        "        self.generate_measures_plots()\n",
        "\n",
        "    def init_tracking_measures(self):\n",
        "        self.tracking_measures = {}\n",
        "        self.tracking_measures['batch_train_loss'] = []\n",
        "        self.tracking_measures['batch_train_acc'] = []\n",
        "        self.tracking_measures['epoch_train_loss'] = []\n",
        "        self.tracking_measures['epoch_train_acc'] = []\n",
        "        self.tracking_measures['epoch_test_loss'] = []\n",
        "        self.tracking_measures['epoch_test_acc'] = []\n",
        "\n",
        "    def generate_measures_plots(self):\n",
        "        for key, value in self.tracking_measures.items():\n",
        "            fig, ax = plt.subplots(figsize=(10, 5))\n",
        "            ax.plot(value)\n",
        "            ax.set_title(key)\n",
        "            plt.grid()\n",
        "            fn = os.path.join(self.Train_Results_Dir,'{}.png'.format(key))\n",
        "            plt.savefig(fn)\n",
        "            plt.close()\n",
        "\n",
        "    def train_epoch(self, net, trainloader, epoch):\n",
        "\n",
        "        epoch_loss = 0\n",
        "        epoch_acc = 0\n",
        "        net.train()\n",
        "        for data in tqdm(trainloader):\n",
        "            # data pixels and labels to GPU if available\n",
        "            inputs, labels = data[0].to(self.device, non_blocking=True), data[1].to(self.device, non_blocking=True)\n",
        "\n",
        "            # set the parameter gradients to zero\n",
        "            self.optimizer.zero_grad()\n",
        "            outputs = net(inputs)\n",
        "            # print(outputs.shape, labels.shape)\n",
        "            loss = self.criterion(outputs, labels)\n",
        "            # propagate the loss backward\n",
        "            loss.backward()\n",
        "            # update the gradients\n",
        "            self.optimizer.step()\n",
        "\n",
        "            batch_loss = loss.item()\n",
        "            epoch_loss += batch_loss\n",
        "            self.tracking_measures['batch_train_loss'].append(batch_loss)\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            batch_acc = (predicted == labels).sum().item()/len(predicted)\n",
        "            epoch_acc += batch_acc\n",
        "            self.tracking_measures['batch_train_acc'].append(batch_acc)\n",
        "\n",
        "        epoch_loss /= len(trainloader)\n",
        "        epoch_acc /= len(trainloader)\n",
        "        print('Train Epoch {} loss: {:.3f} acc: {:.3f}'.format(epoch + 1, epoch_loss, epoch_acc))\n",
        "        self.tracking_measures['epoch_train_loss'].append(epoch_loss)\n",
        "        self.tracking_measures['epoch_train_acc'].append(epoch_acc)\n",
        "\n",
        "        return net\n",
        "\n",
        "\n",
        "    def test_epoch(self, net, testloader, epoch):       \n",
        "        correct = 0\n",
        "        total = 0\n",
        "        epoch_loss = 0\n",
        "        epoch_acc = 0\n",
        "\n",
        "        net.eval()\n",
        "        with torch.no_grad():\n",
        "            for data in testloader:\n",
        "                inputs, labels = data[0].to(self.device, non_blocking=True), data[1].to(self.device, non_blocking=True)\n",
        "                print(inputs.shape, labels.shape)\n",
        "                outputs = net(inputs)\n",
        "                loss = self.criterion(outputs, labels)\n",
        "\n",
        "                # total += labels.size(0)\n",
        "                # correct += (predicted == labels).sum().item()\n",
        "\n",
        "                batch_loss = loss.item()\n",
        "                epoch_loss += batch_loss\n",
        "\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                batch_acc = (predicted == labels).sum().item()/len(predicted)\n",
        "                epoch_acc += batch_acc\n",
        "\n",
        "        # print('Accuracy of the network on test images: %0.3f %%' % (\n",
        "        #         100 * correct / total))\n",
        "        epoch_loss /= len(testloader)\n",
        "        epoch_acc /= len(testloader)\n",
        "        print('Test Epoch {} loss: {:.3f} acc: {:.3f}'.format(epoch + 1, epoch_loss, epoch_acc))\n",
        "        self.tracking_measures['epoch_test_loss'].append(epoch_loss)\n",
        "        self.tracking_measures['epoch_test_acc'].append(epoch_acc)\n",
        "\n",
        "    def get_device(self):\n",
        "        if torch.cuda.is_available():\n",
        "            device = 'cuda:0'\n",
        "        else:\n",
        "            device = 'cpu'\n",
        "        return device\n",
        "\n",
        "    def save_network(self, net, weights_save_path):\n",
        "        saved_dict = {'state_dict': net.state_dict()}\n",
        "        # add custom data to the saved file:\n",
        "        saved_dict['train_measures'] = self.tracking_measures\n",
        "        saved_dict['config'] = self.config\n",
        "        # saved_dict['class2sym_mapper'] = class2sym_mapper\n",
        "\n",
        "        fn = os.path.join(self.Train_Results_Dir,config['state'] +'.pth')\n",
        "        torch.save(saved_dict, fn)\n",
        "        print('save model in ' + fn)\n",
        "\n",
        "        fn = weights_save_path\n",
        "        torch.save(saved_dict, fn)\n",
        "        print('save model in ' + fn)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAVbBxlP8DXC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def download_dataset(config, transform):\n",
        "    if config['state'] == 'MNIST':\n",
        "      import torchvision\n",
        "      train_dataset = torchvision.datasets.MNIST(config['data_path'], train=True, download=True,\n",
        "                            transform=transform)\n",
        "      test_dataset = torchvision.datasets.MNIST(config['data_path'], train=False, download=True,\n",
        "                            transform=transform)                      \n",
        "\n",
        "\n",
        "    if config['state'] == 'HASY':\n",
        "      if not os.path.exists(config['data_path'] + 'hasy-data'): # download data  \n",
        "        import tarfile\n",
        "        import requests    \n",
        "        url = 'https://zenodo.org/record/259444/files/HASYv2.tar.bz2?download=1'\n",
        "        out = config['data_path'] + 'HASYv2.tar'\n",
        "        print('Downloading HASY dataset')\n",
        "        r = requests.get(url)\n",
        "        with open(out, 'wb') as f:\n",
        "            f.write(r.content)\n",
        "        \n",
        "        my_tar = tarfile.open(out)\n",
        "        print('Extracting dataset')\n",
        "        my_tar.extractall(config['data_path'])  # specify which folder to extract to\n",
        "        my_tar.close()\n",
        "        print('Done extracting')\n",
        "        \n",
        "      meta_data = pd.read_csv(config['data_path'] + 'hasy-data-labels.csv')\n",
        "      # here we concatenate all_df with equal sign df\n",
        "      all_df = mapper(meta_data,config['sym_list']) # slice only needed symbols\n",
        "      print(all_df.latex.value_counts())\n",
        "\n",
        "      dataset = HASYDataset(config,all_df,transform) # read data into dataset\n",
        "      train_size = int(config['HASY_train_split'] * len(dataset))\n",
        "      test_size = len(dataset) - train_size\n",
        "      train_dataset, test_dataset = torch.utils.data.random_split(dataset,\n",
        "                                                                  [train_size, test_size]) # split dataset to train and test\n",
        "\n",
        "    return (train_dataset,test_dataset)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1d-i9rM4yaYa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1c959ae7-c6d6-40ef-b4b6-3e87397b1149"
      },
      "source": [
        "inner_path = ''\n",
        "config = {}\n",
        "config['inner_path'] = inner_path\n",
        "config['data_path'] = inner_path + 'DataSets/'\n",
        "config['weights_path'] = inner_path + 'Classifier/weights/'\n",
        "config['train_data_path'] = 'classification-task/fold-1/train.csv'\n",
        "config['test_data_path']  = 'classification-task/fold-1/test.csv'\n",
        "config['batch_size'] = 128\n",
        "config['train_epochs'] = 2\n",
        "config['lr'] = 0.01\n",
        "config['momentum'] = 0.9 \n",
        "config['state'] = 'MNIST'\n",
        "config['sym_list'] = ['1','2','3','4','5','6','7','8','9',\n",
        "                      '\\\\alpha','=','+','-','\\\\pi','A','X','\\\\cdot']\n",
        "config['HASY_train_split'] = 0.8\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                              transforms.Normalize(0.5,0.5),\n",
        "                              ])\n",
        "\n",
        "dataset = download_dataset(config, transform)\n",
        "theTrainer = Trainer(config,dataset)\n",
        "\n",
        "tic = time.time()\n",
        "theTrainer.train()\n",
        "print('Proccess took {:.2f} m.'.format((time.time() - tic)/60))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n",
            "Start Training on cpu\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:21<00:00, 21.84it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch 1 loss: 0.651 acc: 0.802\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([16, 1, 28, 28]) torch.Size([16])\n",
            "Test Epoch 1 loss: 0.092 acc: 0.972\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:21<00:00, 21.92it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch 2 loss: 0.084 acc: 0.974\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([16, 1, 28, 28]) torch.Size([16])\n",
            "Test Epoch 2 loss: 0.052 acc: 0.983\n",
            "save model in Classifier/TrainResults/Train_Results_2020-09-01_08-48-28/MNIST.pth\n",
            "save model in Classifier/weights/MNIST_weights.pth\n",
            "Done Training 2 epochs\n",
            "Proccess took 0.82 m.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sxu9La5H0l8l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "170b0bd7-a610-4bf1-f029-6e398adf681b"
      },
      "source": [
        "config['state'] = 'HASY'\n",
        "\n",
        "transform = transforms.Compose([transforms.Resize([28,28]),                                \n",
        "                      transforms.ToTensor(),\n",
        "                      transforms.Normalize(0.5,0.5),\n",
        "                      ])\n",
        "\n",
        "dataset = download_dataset(config, transform)\n",
        "theTrainer = Trainer(config,dataset)\n",
        "\n",
        "tic = time.time()\n",
        "theTrainer.train()\n",
        "print('Proccess took {:.2f} m.'.format((time.time() - tic)/60))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading HASY dataset\n",
            "Extracting dataset\n",
            "Done extracting\n",
            "\\alpha    2601\n",
            "\\pi       1533\n",
            "\\cdot      755\n",
            "A          159\n",
            "2          124\n",
            "8          121\n",
            "3          120\n",
            "1          118\n",
            "-          118\n",
            "6          100\n",
            "+           90\n",
            "9           90\n",
            "5           78\n",
            "7           75\n",
            "4           61\n",
            "X           54\n",
            "Name: latex, dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  3%|▎         | 1/39 [00:00<00:04,  8.69it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n",
            "Start Training on cpu\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 39/39 [00:03<00:00, 11.19it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch 1 loss: 1.484 acc: 0.616\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([88, 1, 28, 28]) torch.Size([88])\n",
            "Test Epoch 1 loss: 0.915 acc: 0.752\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 39/39 [00:03<00:00, 11.71it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch 2 loss: 0.764 acc: 0.774\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
            "torch.Size([88, 1, 28, 28]) torch.Size([88])\n",
            "Test Epoch 2 loss: 0.677 acc: 0.784\n",
            "save model in Classifier/TrainResults/Train_Results_2020-09-01_08-50-15/HASY.pth\n",
            "save model in Classifier/weights/HASY_weights.pth\n",
            "Done Training 2 epochs\n",
            "Proccess took 0.17 m.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}